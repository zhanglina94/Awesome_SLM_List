{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231db286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下载llama"
  "!pip install -U llama-cpp-python\n",
   ]
  },
 
  {
   "cell_type": "markdown",
   "id": "9e6af07f",
   "metadata": {},
   "source": [
    "# 下载预训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2175f54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama\n",
    "from PIL import Image\n",
    "\n",
    "llm = Llama.from_pretrained(\n",
    "    repo_id="lmstudio-community/gemma-3-270m-it-qat-GGUF",\n",
    "        filename="gemma-3-270m-it-qat-Q4_0.gguf"\n",
    ")\n",
    "\n",
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2175f54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama\n",
    "from PIL import Image\n",
    "\n",
    "llm = Llama.from_pretrained(\n",
    "    repo_id="lmstudio-community/gemma-3-270m-it-qat-GGUF",\n",
    "        filename="gemma-3-270m-it-qat-Q4_0.gguf"\n",
    ")\n",
    "\n",
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2175f54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.create_chat_completion(\n",
    "    messages=[\n",
    "        {"role": "user", "content": "What is the capital of France?"},\n",
    "        {"role": "assistant", "content": "The capital of France is Paris."},\n",
    "        {"role": "user", "content": "What is the population of Paris?"}\n",
    "    ]\n",
    ")\n",
    "\n",
   ]
  },
 
 "nbformat": 4,
 "nbformat_minor": 5
}
